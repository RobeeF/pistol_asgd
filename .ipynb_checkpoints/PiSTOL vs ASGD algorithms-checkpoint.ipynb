{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PiSTOL vs ASGD algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from time import time\n",
    "import sys as sys\n",
    "from scipy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "import os \n",
    "os.chdir('C:/Users/robin/Documents/Documents_importants/scolarit√©/ENSAE3A_DataScience/MasterDS/Semestre 2/optimisation/TPs/TP1')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed\n",
    "np.random.seed(94)\n",
    "\n",
    "# choose a large font size by default and use tex for math\n",
    "usetex = False # change this to True if you have a working LaTeX install\n",
    "\n",
    "fontsize = 18\n",
    "params = {'axes.labelsize': fontsize + 2,\n",
    "      'font.size': fontsize + 2,\n",
    "      'legend.fontsize': fontsize + 2,\n",
    "      'xtick.labelsize': fontsize,\n",
    "      'ytick.labelsize': fontsize,\n",
    "      'text.usetex': True}\n",
    "plt.rcParams.update(params)\n",
    "plt.rc('font', family='Times New Roman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "mat = scipy.io.loadmat('data_orsay_2017.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data in correct format \n",
    "X_test = mat['Xtest']\n",
    "Y_test = mat['ytest']\n",
    "X_train = mat['Xtrain']\n",
    "Y_train = mat['ytrain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_obs = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASGD implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_1_sqrtn(n):\n",
    "    ''' Step size function'''\n",
    "    return (1/np.sqrt(n))\n",
    "\n",
    "def quad_loss(theta,y,x):\n",
    "    ''' Returns the quadratic loss'''\n",
    "    return .5*np.mean((y-np.dot(x,theta.reshape(-1,1)))**2)\n",
    "\n",
    "def grad_quad_loss_sgd(theta,y,x):\n",
    "    ''' Returns the gradient of the quadratic loss  '''\n",
    "    return np.mean(-x*(y-np.dot(x,theta.reshape(-1,1))),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(theta_init, y, x, grad, n_iter, step, store_every=1, avg=False, cyclic=False):\n",
    "    \"\"\"Gradient descent algorithm.\"\"\"\n",
    "    theta = theta_init.copy()\n",
    "    theta_avg = 0\n",
    "    theta_list = []\n",
    "    n = x.shape[0]\n",
    "\n",
    "    for j in range(1,n_iter+1):\n",
    "        chosen_idx = np.random.choice(n) if cyclic==False else (j-1)%n\n",
    "        theta = theta - step(j) * grad(theta, y[chosen_idx],x[chosen_idx,:])\n",
    "        if avg:\n",
    "            theta_avg = (1-1/j)*theta_avg + (1/j)*theta\n",
    "        if j % store_every == 0:\n",
    "            if avg:\n",
    "                theta_list.append(theta_avg.copy())\n",
    "            else:\n",
    "                theta_list.append(theta.copy())\n",
    "    return (theta, theta_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = rate_1_sqrtn\n",
    "\n",
    "theta_init = np.full(100,0)\n",
    "estimates_avg = sgd(theta_init,Y_train,X_train,grad_quad_loss_sgd,n_iter=nb_obs,step=rate_1_sqrtn,store_every=1,avg=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_sgd_avg = []\n",
    "for coef in estimates_avg:\n",
    "    test_error_sgd_avg.append(quad_loss(coef, Y_test, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PiSTOL implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, y, gamma=0.04):\n",
    "    ''' Compute K '''\n",
    "    return np.exp(-gamma*np.linalg.norm(x-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(X):\n",
    "    ''' compute k(.,.) for each of the n observations\n",
    "    Taken from mblondel's Github (percepetron repo)'''\n",
    "    n_samples = X.shape[0]\n",
    "    K = np.zeros((n_samples, n_samples))\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            K[i,j] = gaussian_kernel(X[i], X[j])\n",
    "    return K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = compute_kernel(X_train[:nb_obs,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pistol(y, x, grad, n_iter, L, mu=0, store_every=1, b=1):\n",
    "    \"\"\"Gradient descent algorithm.\"\"\"\n",
    "    n, d = x.shape\n",
    "    a = 0.25\n",
    "    beta = np.sqrt(2*a*L*n) # Make only one pass over the data\n",
    "    alpha = a*L\n",
    "    \n",
    "    f = np.zeros((n_iter,n))\n",
    "    g = np.zeros((n_iter, n))\n",
    "    \n",
    "    for t in range(1, n_iter):\n",
    "\n",
    "        f[t] = g[t-1]*(b/alpha)*np.exp(gaussian_kernel(g[t-1], np.zeros(n))**2/(2*alpha)) \n",
    "        y_pred = f[t,t%n] # f[t,t%n] might me better\n",
    "                \n",
    "        s_t =  grad(y_pred, y[t])\n",
    "        # Updates\n",
    "        g[t] = g[t-1] - s_t*kernel[t]\n",
    "        alpha = alpha + a*np.abs(s_t)*gaussian_kernel(kernel[t], np.zeros(n)) \n",
    "    return f#np.mean(f,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = nb_obs\n",
    "f_history = pistol(Y_train[:nb_obs], X_train[:nb_obs], grad=grad_quad_loss, n_iter=n_iter, L=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pistol_history = []\n",
    "for i in range(n_iter):\n",
    "    pistol_history.append(np.mean(f_history[:i,:],axis=0))\n",
    "pistol_history = np.nan_to_num(pistol_history)\n",
    "pistol_history[pistol_history==0] = 5 # Initiate the first predictions as positive predictions (g_0=0 give no sign...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_history = np.sign(pistol_history)\n",
    "test_error_pistol = []\n",
    "for i in range(n_iter):\n",
    "    test_error_pistol.append(quad_loss(preds_history[i,:],Y_train[:nb_obs].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(test_error_pistol, lw=2)\n",
    "plt.plot(test_error_sgd_avg, lw=2)\n",
    "plt.title(\"ASGD vs PiSTOL unpenalized quadratic loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Objective\")\n",
    "plt.legend([\"PiSTOL\", \"ASGD\"])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('comp_asgd_pistol.png', format='png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
